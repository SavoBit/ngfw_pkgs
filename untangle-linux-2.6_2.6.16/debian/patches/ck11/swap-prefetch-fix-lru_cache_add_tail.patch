From akpm@osdl.org Thu May 18 17:57:05 2006
Return-Path: <akpm@osdl.org>
X-Original-To: kernel@kolivas.org
Delivered-To: kernel@kolivas.org
Received: from bhhdoa.org.au (bhhdoa.org.au [65.98.99.88])
	by mail.kolivas.org (Postfix) with ESMTP id 8B7BAC60BD
	for <kernel@kolivas.org>; Thu, 18 May 2006 17:57:12 +1000 (EST)
Received: from smtp.osdl.org (smtp.osdl.org [65.172.181.4])
	by bhhdoa.org.au (Postfix) with ESMTP id 3FB7E517F9
	for <kernel@kolivas.org>; Thu, 18 May 2006 15:53:28 +1000 (EST)
Received: from shell0.pdx.osdl.net (fw.osdl.org [65.172.181.6])
	by smtp.osdl.org (8.12.8/8.12.8) with ESMTP id k4I7v5tH000982
	(version=TLSv1/SSLv3 cipher=EDH-RSA-DES-CBC3-SHA bits=168 verify=NO);
	Thu, 18 May 2006 00:57:06 -0700
Received: from localhost.localdomain (shell0.pdx.osdl.net [10.9.0.31])
	by shell0.pdx.osdl.net (8.13.1/8.11.6) with ESMTP id k4I7v4H0012555;
	Thu, 18 May 2006 00:57:05 -0700
Message-Id: <200605180757.k4I7v4H0012555@shell0.pdx.osdl.net>
Subject: + swap-prefetch-fix-lru_cache_add_tail.patch added to -mm tree
To: a.p.zijlstra@chello.nl,
 kernel@kolivas.org,
 mm-commits@vger.kernel.org
From: akpm@osdl.org
Date: Thu, 18 May 2006 00:57:05 -0700
X-Spam-Status: No, hits=1.088 required=5 tests=NO_REAL_NAME
X-Spam-Level: *
X-Spam-Checker-Version: SpamAssassin 2.63-osdl_revision__1.74__
X-MIMEDefang-Filter: osdl$Revision: 1.134 $
X-Scanned-By: MIMEDefang 2.36
X-DSPAM-Result: Whitelisted
X-DSPAM-Confidence: 0.9997
X-DSPAM-Probability: 0.0000
X-DSPAM-Signature: 446c28db96851907813259
X-DSPAM-Factors: 27,
	var+lru, 0.00010,
	var+lru, 0.00010,
	dirty+pages, 0.00010,
	dirty+pages, 0.00010,
	tail+struct, 0.00010,
	tail+struct, 0.00010,
	put+cpu, 0.00010,
	struct+pagevec, 0.00010,
	struct+pagevec, 0.00010,
	deletion+diff, 0.00010,
	devel+mm, 0.00010,
	pagevec, 0.00010,
	pagevec, 0.00010,
	pvec+get, 0.00010,
	pvec+get, 0.00010,
	add+active, 0.00010,
	add+active, 0.00010,
	pvecs, 0.00010,
	pvecs, 0.00010,
	From+Peter, 0.00010,
	static+DEFINE, 0.00010,
	static+DEFINE, 0.00010,
	add+pvec, 0.00010,
	tail+pvec, 0.00010,
	add+struct, 0.00010,
	pagevec+lru, 0.00010,
	pagevec+lru, 0.00010
X-UID: 19440
X-Length: 5060
Status: R
X-Status: NC
X-KMail-EncryptionState:  
X-KMail-SignatureState:  
X-KMail-MDN-Sent:  


The patch titled

     swap-prefetch: fix lru_cache_add_tail()

has been added to the -mm tree.  Its filename is

     swap-prefetch-fix-lru_cache_add_tail.patch

See http://www.zip.com.au/~akpm/linux/patches/stuff/added-to-mm.txt to find
out what to do about this


From: Peter Zijlstra <a.p.zijlstra@chello.nl>

lru_cache_add_tail() uses the inactive per-cpu pagevec.  This causes normal
inactive and intactive tail inserts to end up on the wrong end of the list.

When the pagevec is completed by lru_cache_add_tail() but still contains
normal inactive pages, all pages will be added to the inactive tail and
vice versa.

Also *add_drain*() will always complete to the inactive head.

Add a third per-cpu pagevec to alleviate this problem.

Signed-off-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
Acked-by: Con Kolivas <kernel@kolivas.org>
Signed-off-by: Andrew Morton <akpm@osdl.org>
---

 mm/swap.c |    8 +++++++-
 1 files changed, 7 insertions(+), 1 deletion(-)

Index: linux-2.6.16-ck11/mm/swap.c
===================================================================
--- linux-2.6.16-ck11.orig/mm/swap.c	2006-05-21 12:20:15.000000000 +1000
+++ linux-2.6.16-ck11/mm/swap.c	2006-05-21 12:24:27.000000000 +1000
@@ -141,6 +141,7 @@ EXPORT_SYMBOL(mark_page_accessed);
  */
 static DEFINE_PER_CPU(struct pagevec, lru_add_pvecs) = { 0, };
 static DEFINE_PER_CPU(struct pagevec, lru_add_active_pvecs) = { 0, };
+static DEFINE_PER_CPU(struct pagevec, lru_add_tail_pvecs) = { 0, };
 
 void fastcall lru_cache_add(struct page *page)
 {
@@ -162,6 +163,8 @@ void fastcall lru_cache_add_active(struc
 	put_cpu_var(lru_add_active_pvecs);
 }
 
+static inline void __pagevec_lru_add_tail(struct pagevec *pvec);
+
 static void __lru_add_drain(int cpu)
 {
 	struct pagevec *pvec = &per_cpu(lru_add_pvecs, cpu);
@@ -172,6 +175,9 @@ static void __lru_add_drain(int cpu)
 	pvec = &per_cpu(lru_add_active_pvecs, cpu);
 	if (pagevec_count(pvec))
 		__pagevec_lru_add_active(pvec);
+	pvec = &per_cpu(lru_add_tail_pvecs, cpu);
+	if (pagevec_count(pvec))
+		__pagevec_lru_add_tail(pvec);
 }
 
 void lru_add_drain(void)
@@ -417,7 +423,7 @@ static inline void __pagevec_lru_add_tai
  */
 void fastcall lru_cache_add_tail(struct page *page)
 {
-	struct pagevec *pvec = &get_cpu_var(lru_add_pvecs);
+	struct pagevec *pvec = &get_cpu_var(lru_add_tail_pvecs);
 
 	page_cache_get(page);
 	if (!pagevec_add(pvec, page))
